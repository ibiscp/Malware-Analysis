{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Malware Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Import necessary libraries for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os, os.path\n",
    "from collections import defaultdict, OrderedDict\n",
    "from urllib.parse import urlsplit\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "# Set seed for random numbers\n",
    "random.seed(1)\n",
    "\n",
    "# Define folder where the log files are located\n",
    "folder = 'drebin/feature_vectors/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Show basic information about the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset:  129013\n",
      "Number of non malwares:\t 123453\n",
      "Number of malwares:\t 5560\n"
     ]
    }
   ],
   "source": [
    "non_malware = list()\n",
    "malware = list()\n",
    "\n",
    "dataset = os.listdir(folder) # List of all the files\n",
    "\n",
    "# Create malware dictionary with the file name and the type of each one\n",
    "with open('drebin/sha256_family.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    malware_dictionary = {row[0]:row[1] for row in reader}\n",
    "\n",
    "# Separate the file names between malware and non malware\n",
    "for i in dataset:\n",
    "    if i in malware_dictionary:\n",
    "        malware.append(i)\n",
    "    else:\n",
    "        non_malware.append(i)\n",
    "    \n",
    "print('Size of dataset: ', len(malware) + len(non_malware))\n",
    "print('Number of non malwares:\\t', len(non_malware))\n",
    "print('Number of malwares:\\t', len(malware))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Malware categories\n",
    "Just to have an idea of the dataset, below is presented a list of how many samples there are in each malware class. This data will not be used for this project, but further development could be done in order to classify the class each malware belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of entries in each class of malware (values above 20):\n",
      "\t 925 FakeInstaller\n",
      "\t 667 DroidKungFu\n",
      "\t 625 Plankton\n",
      "\t 613 Opfake\n",
      "\t 339 GinMaster\n",
      "\t 330 BaseBridge\n",
      "\t 152 Iconosys\n",
      "\t 147 Kmin\n",
      "\t 132 FakeDoc\n",
      "\t  92 Geinimi\n",
      "\t  91 Adrd\n",
      "\t  81 DroidDream\n",
      "\t  70 ExploitLinuxLotoor\n",
      "\t  69 Glodream\n",
      "\t  69 MobileTx\n",
      "\t  61 FakeRun\n",
      "\t  59 SendPay\n",
      "\t  58 Gappusin\n",
      "\t  43 Imlog\n",
      "\t  41 SMSreg\n",
      "\t  37 Yzhc\n",
      "\t  29 Jifake\n",
      "\t  28 Hamob\n",
      "\t  27 Boxer\n",
      "\t 775 Others\n"
     ]
    }
   ],
   "source": [
    "print('\\nNumber of entries in each class of malware (values above 20):')\n",
    "\n",
    "v = defaultdict(list)\n",
    "for key, value in sorted(malware_dictionary.items()):\n",
    "    v[value].append(key)\n",
    "ordered_v = OrderedDict(sorted(v.items(), key=lambda x: len(x[1]), reverse=True))\n",
    "count_malware = 0\n",
    "for k in ordered_v:\n",
    "    if len(v[k])>20: # Print only classes with more than 20 examples\n",
    "        count_malware += len(v[k])\n",
    "        print('\\t', '{:>3}'.format(len(v[k])), k)\n",
    "        \n",
    "print('\\t', '{:>3}'.format(len(malware) - count_malware), 'Others')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create the training and test set\n",
    "It is possible to notice that the number of non malware data in the dataset is much larger than the number of malware examples. In order to have a balanced dataset, random number of non malware examples will be selected from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Generate random numbers\n",
    "index = random.sample(range(0, len(non_malware)-1), len(malware))\n",
    "\n",
    "# New list with malware and non malware examples divided \n",
    "non_malware = [non_malware[i] for i in index]\n",
    "\n",
    "# Merged list containing malware and non malware\n",
    "data = malware + non_malware\n",
    "\n",
    "# Vector with class of each example\n",
    "y = [1]*len(malware) + [0]*len(non_malware)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## List of categories\n",
    "This is an example of one file containing the features extracted from the application. These features are extracted from the `manifest.xml` file and from the disassembled code.\n",
    "\n",
    "```\n",
    "00a25c24961da2d9ac3824df93deeb99ef5b8e045d3dcdeb8a0afa30184c69bd\n",
    "\n",
    "feature::android.hardware.touchscreen\n",
    "api_call::android/content/Context;->startService\n",
    "activity::.BatteryClockActivity\n",
    "activity::Choice Application !!\n",
    "intent::android.intent.action.MAIN\n",
    "activity::.LaunchDialog\n",
    "intent::android.intent.action.USER_PRESENT\n",
    "intent::android.intent.category.LAUNCHER\n",
    "real_permission::android.permission.VIBRATE\n",
    "api_call::android/app/NotificationManager;->notify\n",
    "provider::android.appwidget.provider\n",
    "call::getSystemService\n",
    "service_receiver::.BatteryClockService\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features can be divided in 10 different sets:\n",
      "\t api_call\n",
      "\t feature\n",
      "\t url\n",
      "\t service_receiver\n",
      "\t permission\n",
      "\t call\n",
      "\t intent\n",
      "\t real_permission\n",
      "\t activity\n",
      "\t provider\n"
     ]
    }
   ],
   "source": [
    "category_list = list()\n",
    "\n",
    "for file in dataset[0:20]:\n",
    "    with open(folder + file) as f:\n",
    "        content = f.readlines()\n",
    "        for line in content:\n",
    "            category, string = line.split('::')\n",
    "            if category not in category_list:\n",
    "                category_list.append(category)\n",
    "print('The features can be divided in 10 different sets:')\n",
    "print('\\t','\\n\\t '.join(category_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here the list of features to be considered is declared, in order to change the features to be considered it is necessary to set the flags to `True` or `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "features = {\n",
    "    'api_call': True,\n",
    "    'feature': True,\n",
    "    'url': True,\n",
    "    'service_receiver': True,\n",
    "    'permission': True,\n",
    "    'call': True,\n",
    "    'intent': True,\n",
    "    'real_permission': True,\n",
    "    'activity': True,\n",
    "    'provider': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Extract useful data\n",
    "The functions listed below are used to extract the data necessary to classify the malware. It gets each line of the files based on the category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Extract url\n",
    "def extract_url(string):\n",
    "    try:\n",
    "        #string = ''.join(e for e in string if e.isalnum())\n",
    "        base_url = \"{0.scheme}://{0.netloc}/\".format(urlsplit(string))\n",
    "        if len(base_url) > 10:\n",
    "            return [base_url]\n",
    "    except:\n",
    "        #print('Error html: ', string)\n",
    "        return None\n",
    "    \n",
    "# Extract api_call\n",
    "def extract_api_call(string):\n",
    "    try:\n",
    "        string = string.replace(';->', '/')\n",
    "        api_call = string.split('/')\n",
    "        return api_call\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "# Extract feature\n",
    "def extract_feature(string):\n",
    "    try:\n",
    "        feature = string.split('.')[-1]\n",
    "        return [feature]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "# Extract permission and real_permission\n",
    "def extract_permission(string):\n",
    "    try:\n",
    "        permission = string.split('.')[-1].lower()\n",
    "        return [permission]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Extract call\n",
    "def extract_call(string):\n",
    "    try:\n",
    "        call = string.lower()\n",
    "        '''par = call.find( '(' )\n",
    "        if par != -1:\n",
    "            call = call[:par]'''\n",
    "        return [call]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "# Extract activity\n",
    "def extract_activity(string):\n",
    "    try:\n",
    "        activity = string.split('.')[-1].lower()\n",
    "        return [activity]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "# Extract intent\n",
    "def extract_intent(string):\n",
    "    try:\n",
    "        intent = string.split('.')[-1].lower()\n",
    "        return [intent]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "# Extract service_receiver\n",
    "def extract_service_receiver(string):\n",
    "    try:\n",
    "        service_receiver = string.split('.')[-1].lower()\n",
    "        return [service_receiver]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "# Extract provider\n",
    "def extract_provider(string):\n",
    "    try:\n",
    "        provider = string.split('.')[-1].lower()\n",
    "        return [provider]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Map words to index\n",
    "It is important to create a dictionary with all the words containing in the files and convert each file to a vector of the index of each word in the dictionary, as show in the example below:\n",
    "```\n",
    "000068216bdb459df847bfdd67dd11069c3c50166db1ea8772cdc9250d948bcf\n",
    "[3, 55, 56, 11, 13, 57, 22, 58, 59, 52, 60, 61, 4, 5, 6, 62, 63, 64, 49, 50, 51, 40, 41, 65, 47, 53]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_file(file, dictionary_creation = False):\n",
    "\n",
    "    # List of words of each file\n",
    "    words = list()\n",
    "    \n",
    "    # Read line by line of the file\n",
    "    with open(folder + file) as f:\n",
    "        content = f.readlines()\n",
    "        \n",
    "        # Divide each line of document in \n",
    "        for line in content:\n",
    "            try:\n",
    "                split = line.split('::')\n",
    "                category = split[0]\n",
    "                string = split[1]\n",
    "            except:\n",
    "                break\n",
    "                \n",
    "            # Only process the categories selected by the user\n",
    "            if (features[category]):\n",
    "                if (category == 'url'):\n",
    "                    word_list = extract_url(string)\n",
    "                elif (category == 'api_call'):\n",
    "                    word_list = extract_api_call(string)\n",
    "                elif (category == 'feature'):\n",
    "                    word_list = extract_feature(string)\n",
    "                elif (category == 'permission' or category == 'real_permission'):\n",
    "                    word_list = extract_permission(string)\n",
    "                elif (category == 'call'):\n",
    "                    word_list = extract_call(string)\n",
    "                elif (category == 'activity'):\n",
    "                    word_list = extract_activity(string)\n",
    "                elif (category == 'intent'):\n",
    "                    word_list = extract_intent(string)\n",
    "                elif (category == 'service_receiver'):\n",
    "                    word_list = extract_service_receiver(string)\n",
    "                elif (category == 'provider'):\n",
    "                    word_list = extract_provider(string)\n",
    "\n",
    "                if word_list != None:\n",
    "                    for word in word_list:\n",
    "                        word = word.replace('\\n', '')\n",
    "\n",
    "                        if dictionary_creation:\n",
    "                            index = len(dictionary)-1\n",
    "                            dictionary[word] = index\n",
    "                        else:\n",
    "                            index = dictionary[word]\n",
    "                            if index not in words:\n",
    "                                words.append(index)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create dictionary\n",
    "In order to classify the words, first the dictionary needs to be created using the words of the files that it will classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary file found!\n",
      "Dictionary size:  28959\n"
     ]
    }
   ],
   "source": [
    "# Save dictionary to file\n",
    "def save_dic(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Load dictionary from file\n",
    "def load_dic(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "# Check if dictionary exists\n",
    "if os.path.isfile('dictionary.pkl'):\n",
    "    print('Dictionary file found!')\n",
    "    dictionary = load_dic('dictionary')\n",
    "\n",
    "else:\n",
    "    print('Dictionary file not found!')\n",
    "    \n",
    "    # Define the dictionary\n",
    "    dictionary = {}\n",
    "    \n",
    "    # Colect words for malware\n",
    "    pbar = tqdm(range(len(data)))\n",
    "    pbar.set_description('Creating dictionary')\n",
    "    for i in pbar:\n",
    "        process_file(data[i], True)\n",
    "        \n",
    "    # Save dictionary\n",
    "    save_dic(dictionary, 'dictionary')\n",
    "    print('Dictionary saved to file!\\n')\n",
    "    \n",
    "dictionary_size = len(dictionary)\n",
    "print('Dictionary size: ', dictionary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Features extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|███████████████████████████████████████████████████████| 11120/11120 [07:41<00:00, 24.08it/s]\n"
     ]
    }
   ],
   "source": [
    "def features_extraction(file):\n",
    "    indices = process_file(file)\n",
    "    \n",
    "    feat = [0] * dictionary_size\n",
    "    \n",
    "    for i in indices:\n",
    "        feat[i-1] = 1\n",
    "\n",
    "    return feat\n",
    "\n",
    "X = list()\n",
    "\n",
    "pbar = tqdm(range(len(data)))\n",
    "pbar.set_description('Extracting features')\n",
    "for i in pbar:\n",
    "    feat = features_extraction(data[i])\n",
    "    X.append(feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.29 Seconds to train SVM...\n",
      "Test Accuracy of SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97      1141\n",
      "          1       0.97      0.97      0.97      1083\n",
      "\n",
      "avg / total       0.97      0.97      0.97      2224\n",
      "\n",
      "Test Accuracy of SVM =  0.969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_svm_classifer(features, labels):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
    "    \n",
    "    # Use a linear SVC \n",
    "    svc = svm.LinearSVC()\n",
    "    \n",
    "    # Check the training time for the SVC\n",
    "    t=time.time()\n",
    "    svc.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    print(round(t2-t, 2), 'Seconds to train SVM...')\n",
    "    \n",
    "    # Check the score of the SVC\n",
    "    y_predict=svc.predict(X_test)\n",
    "    \n",
    "    print('\\nTest Accuracy of SVM')\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    \n",
    "    print('Test Accuracy of SVM = ', round(svc.score(X_test, y_test), 4))\n",
    "\n",
    "train_svm_classifer(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66 Seconds to train Naive Bayes...\n",
      "\n",
      "Test Accuracy of Naive Bayes\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.84      0.91      1127\n",
      "          1       0.86      0.99      0.92      1097\n",
      "\n",
      "avg / total       0.93      0.92      0.92      2224\n",
      "\n",
      "Test Accuracy of Naive Bayes =  0.9159\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB#GaussianNB\n",
    "\n",
    "def train_naive_bayes_classifer(features, labels):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
    "    \n",
    "    gnb = MultinomialNB()\n",
    "    \n",
    "    # Check the training time for the SVC\n",
    "    t=time.time()\n",
    "    gnb.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    print(round(t2-t, 2), 'Seconds to train Naive Bayes...')\n",
    "    \n",
    "    # Check the score of the SVC\n",
    "    y_predict=gnb.predict(X_test)\n",
    "    \n",
    "    print('\\nTest Accuracy of Naive Bayes')\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    \n",
    "    print('Test Accuracy of Naive Bayes = ', round(gnb.score(X_test, y_test), 4))\n",
    "\n",
    "train_naive_bayes_classifer(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
